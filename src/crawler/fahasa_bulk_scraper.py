"""
FAHASA BULK SCRAPER - THU TH·∫¨P QUY M√î L·ªöN
T·ªëi ∆∞u cho vi·ªác thu th·∫≠p nhi·ªÅu s√°ch t·ª´ danh m·ª•c ch√≠nh v·ªõi pagination
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import random
import json
import pandas as pd
from datetime import datetime
import json
import re
import os
import psycopg2
from insert_staging_book import insert_book_staging

def extract_price_smart(price_text):
    """Tr√≠ch xu·∫•t gi√° th√¥ng minh"""
    try:
        if not price_text:
            return 0.0
        
        clean_text = re.sub(r'[^\d,.]', '', str(price_text))
        clean_text = clean_text.replace(',', '').replace('.', '')
        
        if clean_text and clean_text.isdigit():
            price = float(clean_text)
            if price < 1000:
                price *= 1000
            return price if price >= 1000 else 0.0
        return 0.0
    except:
        return 0.0

def get_book_details(driver, url):
    """L·∫•y chi ti·∫øt s√°ch t·ª´ URL"""
    try:
        driver.get(url)
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.TAG_NAME, "h1"))
        )
        # Kh·ªüi t·∫°o d·ªØ li·ªáu
        book = {
            'title': '',
            'author': '',
            'publisher': '',
            'supplier': '',
            'category_1': 'S√°ch trong n∆∞·ªõc',
            'category_2': '',
            'category_3': '',
            'original_price': 0.0,
            'discount_price': 0.0,
            'discount_percent': 0.0,
            'rating': 0.0,
            'rating_count': 0,
            'sold_count': '',
            'sold_count_numeric': 0,
            'publish_year': 0,
            'language': 'Ti·∫øng Vi·ªát',
            'page_count': 0,
            'weight': 0.0,
            'dimensions': '',
            'url': url,
            'url_img': '',
            'time_collect': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        # Publish year
        try:
            year_elem = driver.find_element(By.XPATH, "//th[contains(text(), 'NƒÉm XB')]/following-sibling::td")
            divs = year_elem.find_elements(By.TAG_NAME, 'div')
            year_text = ''
            if divs and divs[0].text.strip():
                year_text = divs[0].text.strip()
            elif year_elem.text.strip():
                year_text = year_elem.text.strip()
            if year_text.isdigit():
                book['publish_year'] = int(year_text)
        except:
            pass
        # Weight
        try:
            weight_elem = driver.find_element(By.XPATH, "//th[contains(text(), 'Tr·ªçng l∆∞·ª£ng')]/following-sibling::td")
            divs = weight_elem.find_elements(By.TAG_NAME, 'div')
            weight_text = ''
            if divs and divs[0].text.strip():
                weight_text = divs[0].text.strip()
            elif weight_elem.text.strip():
                weight_text = weight_elem.text.strip()
            weight_val = re.sub(r'[^\d.]', '', weight_text)
            if weight_val:
                weight_gram = float(weight_val)
                if weight_gram > 10:
                    book['weight'] = round(weight_gram / 1000, 3)
                else:
                    book['weight'] = weight_gram
        except:
            pass
        # Dimensions
        try:
            dim_elem = driver.find_element(By.XPATH, "//th[contains(text(), 'K√≠ch Th∆∞·ªõc Bao B√¨')]/following-sibling::td")
            divs = dim_elem.find_elements(By.TAG_NAME, 'div')
            if divs and divs[0].text.strip():
                book['dimensions'] = divs[0].text.strip()
            elif dim_elem.text.strip():
                book['dimensions'] = dim_elem.text.strip()
        except:
            pass
        # Page count
        try:
            page_count_elem = driver.find_element(By.XPATH, "//th[contains(text(), 'S·ªë trang')]/following-sibling::td")
            divs = page_count_elem.find_elements(By.TAG_NAME, 'div')
            if divs and divs[0].text.strip().isdigit():
                book['page_count'] = int(divs[0].text.strip())
            elif page_count_elem.text.strip().isdigit():
                book['page_count'] = int(page_count_elem.text.strip())
        except:
            pass
        
        # L·∫•y breadcrumb (category)
        try:
            breadcrumbs = driver.find_elements(By.CSS_SELECTOR, '.breadcrumb li a')
            if len(breadcrumbs) >= 2:
                book['category_2'] = breadcrumbs[1].text.strip() if len(breadcrumbs) > 1 else ''
                if len(breadcrumbs) == 4:
                    # Gh√©p m·ª•c 3 v√† 4
                    book['category_3'] = f"{breadcrumbs[2].text.strip()} - {breadcrumbs[3].text.strip()}"
                elif len(breadcrumbs) > 2:
                    book['category_3'] = breadcrumbs[2].text.strip()
        except:
            pass
        
        # L·∫•y title
        try:
            title_elem = driver.find_element(By.TAG_NAME, 'h1')
            book['title'] = title_elem.text.strip()
        except:
            return None
        
        # L·∫•y gi√° - th·ª≠ nhi·ªÅu c√°ch
        price_found = False
        
        # C√°ch 1: T√¨m trong element c√≥ ch·ªØ "ƒë"
        try:
            price_elements = driver.find_elements(By.XPATH, "//*[contains(text(), 'ƒë')]")
            for elem in price_elements:
                text = elem.text.strip()
                if re.search(r'\d{2,}', text):  # C√≥ √≠t nh·∫•t 2 ch·ªØ s·ªë
                    price = extract_price_smart(text)
                    if price > 0:
                        book['discount_price'] = price
                        book['original_price'] = price
                        price_found = True
                        break
        except:
            pass
        
        # C√°ch 2: T√¨m trong CSS selector
        if not price_found:
            selectors = [
                '.price-original .price',
                '.price .current-price', 
                '.product-price .price',
                '[data-price]',
                '.price-box .price'
            ]
            
            for selector in selectors:
                try:
                    elem = driver.find_element(By.CSS_SELECTOR, selector)
                    text = elem.text.strip() or elem.get_attribute('data-price') or ''
                    price = extract_price_smart(text)
                    if price > 0:
                        book['discount_price'] = price
                        book['original_price'] = price
                        price_found = True
                        break
                except:
                    continue
        
        # L·∫•y gi√° hi·ªán t·∫°i, gi√° g·ªëc, ph·∫ßn trƒÉm gi·∫£m gi√°
        try:
            # Gi√° hi·ªán t·∫°i
            price_elem = driver.find_element(By.CSS_SELECTOR, 'span.price[id^="product-price-"]')
            price_text = price_elem.text.strip()
            price_val = re.sub(r'[^\d.]', '', price_text)
            if price_val:
                book['discount_price'] = float(price_val.replace('.', ''))
        except:
            pass
        try:
            # Gi√° g·ªëc
            old_price_elem = driver.find_element(By.CSS_SELECTOR, 'span.price[id^="old-price-"]')
            old_price_text = old_price_elem.text.strip()
            old_price_val = re.sub(r'[^\d.]', '', old_price_text)
            if old_price_val:
                book['original_price'] = float(old_price_val.replace('.', ''))
        except:
            pass
        try:
            # Ph·∫ßn trƒÉm gi·∫£m gi√°
            percent_elem = driver.find_element(By.CSS_SELECTOR, 'span.discount-percent')
            percent_text = percent_elem.text.strip()
            percent_val = re.sub(r'[^\d-]', '', percent_text)
            if percent_val:
                book['discount_percent'] = float(percent_val)
        except:
            pass

        # L·∫•y th√¥ng tin kh√°c
        try:
            # Author
            author_elem = driver.find_element(By.XPATH, "//th[contains(text(), 'T√°c gi·∫£')]/following-sibling::td")
            book['author'] = author_elem.text.strip()
        except:
            pass

        # Publisher
        try:
            pub_elem = driver.find_element(By.XPATH, "//th[contains(text(), 'Nh√† xu·∫•t b·∫£n')]/following-sibling::td")
            book['publisher'] = pub_elem.text.strip()
        except:
            try:
                pub_div = driver.find_element(By.CSS_SELECTOR, 'div.product-view-sa-supplier')
                spans = pub_div.find_elements(By.TAG_NAME, 'span')
                if len(spans) >= 2 and 'Nh√† xu·∫•t b·∫£n' in spans[0].text:
                    book['publisher'] = spans[1].text.strip()
            except:
                pass

        # Supplier
        try:
            sup_div = driver.find_element(By.CSS_SELECTOR, 'div.product-view-sa-supplier')
            # ∆Øu ti√™n l·∫•y supplier t·ª´ th·∫ª <a>
            a_tags = sup_div.find_elements(By.TAG_NAME, 'a')
            if a_tags:
                supplier_text = a_tags[0].text.strip()
                book['supplier'] = supplier_text
            else:
                # N·∫øu kh√¥ng c√≥ th·∫ª <a>, l·∫•y text sau span
                spans = sup_div.find_elements(By.TAG_NAME, 'span')
                if len(spans) >= 2 and 'Nh√† cung c·∫•p' in spans[0].text:
                    book['supplier'] = spans[1].text.strip()
                else:
                    # fallback: l·∫•y to√†n b·ªô text tr·ª´ label
                    text = sup_div.text.replace('Nh√† cung c·∫•p:', '').strip()
                    book['supplier'] = text
        except:
            pass
        
        # L·∫•y supplier (ch·ªâ l·∫•y text, kh√¥ng l·∫•y link)
        try:
            sup_divs = driver.find_elements(By.CSS_SELECTOR, 'div.product-view-sa-supplier')
            for div in sup_divs:
                spans = div.find_elements(By.TAG_NAME, 'span')
                if len(spans) >= 2:
                    label = spans[0].text.strip().lower()
                    value = spans[1].text.strip()
                    if 'nh√† cung c·∫•p' in label:
                        book['supplier'] = value
                    elif 'nh√† xu·∫•t b·∫£n' in label:
                        book['publisher'] = value
        except:
            pass

        # L·∫•y url_img (∆∞u ti√™n src, n·∫øu kh√¥ng c√≥ th√¨ l·∫•y data-src)
        try:
            img_elem = driver.find_element(By.CSS_SELECTOR, 'img.fhs-p-img')
            img_url = img_elem.get_attribute('src')
            if not img_url or 'placeholder' in img_url:
                img_url = img_elem.get_attribute('data-src')
            book['url_img'] = img_url
        except:
            pass
        
        # L·∫•y rating v√† rating_count
        try:
            # L·∫•y ƒëi·ªÉm rating, v√≠ d·ª•: "5/5"
            rating_elem = driver.find_element(By.XPATH, "//div[./span[contains(text(), '/5')]]")
            rating_text = rating_elem.text.strip()
            match = re.search(r'(\d+(?:[.,]\d+)?)(?=\s*/\s*5)', rating_text)
            if match:
                book['rating'] = float(match.group(1).replace(',', '.'))
            else:
                # N·∫øu kh√¥ng c√≥ text, th·ª≠ l·∫•y width style trong .rating
                rating_box = driver.find_element(By.CSS_SELECTOR, '.rating-box .rating')
                style = rating_box.get_attribute('style')
                width_match = re.search(r'width:\s*(\d+)%', style)
                if width_match:
                    percent = int(width_match.group(1))
                    book['rating'] = round(percent / 20, 2)  # 100% = 5.0
        except:
            pass
        
        # L·∫•y s·ªë l∆∞·ª£t b√°n (sold_count, sold_count_numeric)
        try:
            sold_elem = driver.find_element(By.CSS_SELECTOR, 'div.product-view-qty-num')
            sold_text = sold_elem.text.strip()
            # sold_text v√≠ d·ª•: 'ƒê√£ b√°n 4' ho·∫∑c 'ƒê√£ b√°n 10k+'
            match = re.search(r'ƒê√£ b√°n\s*([\d.,]+)(k\+)?', sold_text, re.IGNORECASE)
            if match:
                book['sold_count'] = match.group(1) + (match.group(2) if match.group(2) else '')
                # X·ª≠ l√Ω s·ªë l∆∞·ª£t b√°n d·∫°ng s·ªë ho·∫∑c k+
                if match.group(2):
                    # vd: 10k+ => 10000
                    num = float(match.group(1).replace(',', '.')) * 1000
                    book['sold_count_numeric'] = int(num)
                else:
                    num = match.group(1).replace('.', '').replace(',', '')
                    if num.isdigit():
                        book['sold_count_numeric'] = int(num)
        except:
            pass

        # Ch·ªâ tr·∫£ v·ªÅ n·∫øu c√≥ gi√°
        if price_found:
            return book
        else:
            return None
            
    except Exception as e:
        print(f"    ‚ùå L·ªói khi l·∫•y chi ti·∫øt: {e}")
        return None

def scrape_fahasa_bulk(max_pages=1, books_per_page=3):
    """Thu th·∫≠p Fahasa quy m√¥ l·ªõn v·ªõi pagination"""
    print("üöÄ FAHASA BULK SCRAPER - THU TH·∫¨P QUY M√î L·ªöN")
    print("=" * 60)
    print(f"üìä M·ª•c ti√™u: {max_pages} trang x {books_per_page} s√°ch = t·ªëi ƒëa {max_pages * books_per_page} s√°ch")
    print("=" * 60)
    
    # Chrome setup v·ªõi multiple fallback options
    chrome_options = Options()
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-blink-features=AutomationControlled')
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    
    # Th·ª≠ setup ChromeDriver v·ªõi error handling
    driver = None
    try:
        print("üîß ƒêang setup ChromeDriver...")
        
        # Th·ª≠ method 1: ChromeDriverManager
        try:
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=chrome_options)
        except Exception as e1:
            print(f"‚ö†Ô∏è Method 1 failed: {str(e1)[:100]}...")
            
            # Th·ª≠ method 2: System PATH
            try:
                driver = webdriver.Chrome(options=chrome_options)
            except Exception as e2:
                print(f"‚ö†Ô∏è Method 2 failed: {str(e2)[:100]}...")
                raise Exception("Kh√¥ng th·ªÉ kh·ªüi t·∫°o ChromeDriver")
        
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        driver.set_page_load_timeout(30)
        print("‚úÖ ChromeDriver setup th√†nh c√¥ng!")
        
    except Exception as e:
        print(f"‚ùå L·ªói ChromeDriver: {e}")
        print("üí° Gi·∫£i ph√°p:")
        print("   1. Ch·∫°y: python quick_test.py (test kh√¥ng c·∫ßn Chrome)")
        print("   2. Restart m√°y t√≠nh v√† th·ª≠ l·∫°i")
        print("   3. C·∫≠p nh·∫≠t Chrome browser")
        print("   4. Ki·ªÉm tra antivirus kh√¥ng block chromedriver")
        return
    
    books_data = []
    total_collected = 0
    
    try:
        for page in range(1, max_pages + 1):
            print(f"\nüìÑ TRANG {page}/{max_pages}")
            print("-" * 40)
            
            # URL v·ªõi pagination
            url = f"https://www.fahasa.com/sach-trong-nuoc.html?order=num_orders&limit={books_per_page}&p={page}"
            print(f"üåê Truy c·∫≠p: {url}")
            
            driver.get(url)
            time.sleep(random.uniform(3, 5))  # Random delay
            
            # T√¨m t·∫•t c·∫£ s·∫£n ph·∫©m trong trang
            try:
                products = WebDriverWait(driver, 15).until(
                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.item-inner'))
                )
                print(f"üìö T√¨m th·∫•y {len(products)} s·∫£n ph·∫©m trong trang")
            except:
                print("‚ùå Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m, b·ªè qua trang n√†y")
                continue
            
            # L·∫•y URL t·∫•t c·∫£ s·∫£n ph·∫©m trong trang
            product_urls = []
            for product in products:
                try:
                    link = product.find_element(By.TAG_NAME, 'a')
                    url_product = link.get_attribute('href')
                    if url_product and 'flashsale' not in url_product.lower():
                        product_urls.append(url_product)
                except:
                    continue
            
            print(f"üîó S·∫Ω thu th·∫≠p {len(product_urls)} s√°ch t·ª´ trang {page}")
            
            # Thu th·∫≠p t·ª´ng s√°ch
            page_success = 0
            for i, book_url in enumerate(product_urls, 1):
                print(f"\nüìñ S√°ch {i}/{len(product_urls)} (Trang {page}):")
                
                book_data = get_book_details(driver, book_url)
                if book_data:
                    print(f"    ‚úÖ {book_data['title'][:50]}...")
                    print(f"    üí∞ Gi√°: {book_data['discount_price']:,.0f} VNƒê")
                    try:
                        insert_book_staging(book_data)
                        print("    üü¢ ƒê√£ insert v√†o staging_books (PostgreSQL)")
                    except Exception as e:
                        print(f"    üî¥ L·ªói insert staging_books: {e}")
                    books_data.append(book_data)
                    total_collected += 1
                    page_success += 1
                    time.sleep(random.uniform(2, 4))
                else:
                    print(f"    ‚ùå Kh√¥ng l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu ho·∫∑c kh√¥ng c√≥ gi√°")
            
            print(f"\nüìä K·∫æT QU·∫¢ TRANG {page}: {page_success}/{len(product_urls)} s√°ch th√†nh c√¥ng")
            print(f"üìà T·ªîNG C·ªòNG: {total_collected} s√°ch")
            
            # Break n·∫øu kh√¥ng thu th·∫≠p ƒë∆∞·ª£c g√¨
            if page_success == 0:
                print("‚ö†Ô∏è  Kh√¥ng thu th·∫≠p ƒë∆∞·ª£c s√°ch n√†o, c√≥ th·ªÉ h·∫øt d·ªØ li·ªáu")
                break
            
            # Delay gi·ªØa c√°c trang
            if page < max_pages:
                delay = random.uniform(5, 8)
                print(f"‚è≥ Ch·ªù {delay:.1f}s tr∆∞·ªõc trang ti·∫øp theo...")
                time.sleep(delay)
        
        # Xu·∫•t d·ªØ li·ªáu
        if books_data:
            # G·ªôp v·ªõi d·ªØ li·ªáu c≈© n·∫øu c√≥
            output_file_json = 'fahasa_all_books.json'
            output_file_excel = 'fahasa_all_books.xlsx'
            
            existing_data = []
            if os.path.exists(output_file_json):
                try:
                    with open(output_file_json, 'r', encoding='utf-8') as f:
                        existing_data = json.load(f)
                    print(f"üìÇ ƒê√£ c√≥ {len(existing_data)} s√°ch c≈©")
                except:
                    pass
            
            # G·ªôp d·ªØ li·ªáu (tr√°nh duplicate)
            existing_urls = {book.get('url', '') for book in existing_data}
            new_books = [book for book in books_data if book.get('url', '') not in existing_urls]
            
            all_books = existing_data + new_books
            
            # L∆∞u JSON
            with open(output_file_json, 'w', encoding='utf-8') as f:
                json.dump(all_books, f, ensure_ascii=False, indent=2)
            
            # L∆∞u Excel
            import pandas as pd
            df = pd.DataFrame(all_books)
            df.to_excel(output_file_excel, index=False, engine='openpyxl')
            
            print(f"\nüéâ HO√ÄN T·∫§T!")
            print(f"üìä Thu th·∫≠p m·ªõi: {len(new_books)} s√°ch")
            print(f"üìÇ T·ªïng c·ªông: {len(all_books)} s√°ch")
            print(f"üíæ ƒê√£ l∆∞u: {output_file_json}, {output_file_excel}")
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Ng∆∞·ªùi d√πng d·ª´ng ch∆∞∆°ng tr√¨nh")
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
    finally:
        driver.quit()
        print("üîö ƒê√≥ng tr√¨nh duy·ªát")


if __name__ == "__main__":
    # C·∫§U H√åNH THU TH·∫¨P
    MAX_PAGES = 1
    BOOKS_PER_PAGE = 3

    print("‚öôÔ∏è  C·∫§U H√åNH:")
    print(f"   üìÑ S·ªë trang: {MAX_PAGES}")
    print(f"   üìö S√°ch/trang: {BOOKS_PER_PAGE}")
    print(f"   üéØ T·ªëi ƒëa: {MAX_PAGES * BOOKS_PER_PAGE} s√°ch")
    print()
    
    choice = input("üöÄ B·∫Øt ƒë·∫ßu test thu th·∫≠p? (y/n): ").lower()
    if choice == 'y':
        scrape_fahasa_bulk(MAX_PAGES, BOOKS_PER_PAGE)
    else:
        print("‚ùå H·ªßy b·ªè")