# ğŸ“š Fahasa Web Scraper

Automated data collection system for Fahasa.com with 25 comprehensive data fields.

## âš¡ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Start scraping
python fahasa_optimized.py

# View results
python final_summary.py
```

## ğŸ“ Project Structure

**Core Scripts:**
- `fahasa_optimized.py` - Main scraping engine
- `fahasa_database.py` - SQLite database manager  
- `fix_data.py` - Data quality improvement

**Analysis & Reports:**
- `final_summary.py` - Comprehensive data analysis
- `final_test.py` - System validation

**Output Files:**
- `fahasa_all_books.json` - Consolidated JSON data
- `fahasa_all_books.xlsx` - Excel export
- `fahasa_books.db` - SQLite database (25 fields)

## ğŸ¯ Features

âœ… **25 Data Fields** - Complete book information  
âœ… **Price Extraction** - 100% success rate with CloudFlare bypass  
âœ… **File Consolidation** - Single JSON/Excel output  
âœ… **Duplicate Prevention** - Smart data merging  
âœ… **Quality Assurance** - Automated data validation

## ï¿½ Technical Specifications

- **Technology Stack:** Python 3.12, Selenium WebDriver
- **Database:** SQLite with 25-field schema
- **Export Formats:** JSON, Excel, Database
- **Anti-Detection:** CloudFlare bypass capabilities

## âš ï¸ Usage Guidelines

- Respect website terms of service
- Implement appropriate request delays
- Use data responsibly
- Follow robots.txt guidelines