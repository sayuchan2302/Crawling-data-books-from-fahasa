import json
import re
from fahasa_database import FahasaDatabase

def parse_description_data(description):
    """Parse thÃ´ng tin tá»« trÆ°á»ng description"""
    data = {
        'author': '',
        'publisher': '',
        'supplier': '',
        'publish_year': 0,
        'page_count': 0,
        'weight': 0.0,
        'dimensions': '',
        'original_price': 0.0,
        'discount_price': 0.0
    }
    
    if not description:
        return data
    
    # TÃ¡ch cÃ¡c dÃ²ng
    lines = description.split('\n')
    
    for i, line in enumerate(lines):
        line = line.strip()
        
        # TÃ¡c giáº£
        if 'TÃ¡c giáº£' in line and i + 1 < len(lines):
            data['author'] = lines[i + 1].strip()
        
        # NhÃ  xuáº¥t báº£n
        if 'NXB' in line and i + 1 < len(lines):
            data['publisher'] = lines[i + 1].strip()
        
        # NhÃ  cung cáº¥p
        if 'NhÃ  Cung Cáº¥p' in line and i + 1 < len(lines):
            data['supplier'] = lines[i + 1].strip()
        elif 'TÃªn NhÃ  Cung Cáº¥p' in line and i + 1 < len(lines):
            data['supplier'] = lines[i + 1].strip()
        
        # NÄƒm xuáº¥t báº£n
        if 'NÄƒm XB' in line and i + 1 < len(lines):
            try:
                year_text = lines[i + 1].strip()
                data['publish_year'] = int(re.search(r'\d{4}', year_text).group()) if re.search(r'\d{4}', year_text) else 0
            except:
                pass
        
        # Sá»‘ trang
        if 'Sá»‘ trang' in line and i + 1 < len(lines):
            try:
                page_text = lines[i + 1].strip()
                data['page_count'] = int(re.search(r'\d+', page_text).group()) if re.search(r'\d+', page_text) else 0
            except:
                pass
        
        # Trá»ng lÆ°á»£ng
        if 'Trá»ng lÆ°á»£ng' in line and i + 1 < len(lines):
            try:
                weight_text = lines[i + 1].strip()
                weight_match = re.search(r'(\d+)', weight_text)
                if weight_match:
                    data['weight'] = float(weight_match.group()) / 1000  # Convert gram to kg
            except:
                pass
        
        # KÃ­ch thÆ°á»›c
        if 'KÃ­ch ThÆ°á»›c' in line and i + 1 < len(lines):
            data['dimensions'] = lines[i + 1].strip()
    
    return data

def fix_json_data(json_file_path):
    """Fix dá»¯ liá»‡u trong file JSON"""
    print(f"ğŸ”§ FIXING Dá»® LIá»†U JSON: {json_file_path}")
    print("=" * 50)
    
    # Äá»c file JSON
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            books_data = json.load(f)
        
        print(f"ğŸ“š ÄÃ£ Ä‘á»c {len(books_data)} sÃ¡ch tá»« file JSON")
        
        # Fix tá»«ng sÃ¡ch
        fixed_count = 0
        for i, book in enumerate(books_data):
            print(f"\nğŸ“– Äang fix sÃ¡ch {i+1}: {book['title']}")
            
            # Parse description
            parsed_data = parse_description_data(book['description'])
            
            # Cáº­p nháº­t cÃ¡c trÆ°á»ng trá»‘ng
            updates = []
            
            if not book['author'] and parsed_data['author']:
                book['author'] = parsed_data['author']
                updates.append(f"TÃ¡c giáº£: {parsed_data['author']}")
            
            if not book['publisher'] and parsed_data['publisher']:
                book['publisher'] = parsed_data['publisher']
                updates.append(f"NXB: {parsed_data['publisher']}")
            
            if not book['supplier'] or book['supplier'] == 'Fahasa':
                if parsed_data['supplier']:
                    book['supplier'] = parsed_data['supplier']
                    updates.append(f"NhÃ  cung cáº¥p: {parsed_data['supplier']}")
            
            if book['publish_year'] == 0 and parsed_data['publish_year'] > 0:
                book['publish_year'] = parsed_data['publish_year']
                updates.append(f"NÄƒm XB: {parsed_data['publish_year']}")
            
            if book['page_count'] == 0 and parsed_data['page_count'] > 0:
                book['page_count'] = parsed_data['page_count']
                updates.append(f"Sá»‘ trang: {parsed_data['page_count']}")
            
            if book['weight'] == 0.0 and parsed_data['weight'] > 0:
                book['weight'] = parsed_data['weight']
                updates.append(f"Trá»ng lÆ°á»£ng: {parsed_data['weight']} kg")
            
            if not book['dimensions'] and parsed_data['dimensions']:
                book['dimensions'] = parsed_data['dimensions']
                updates.append(f"KÃ­ch thÆ°á»›c: {parsed_data['dimensions']}")
            
            if updates:
                fixed_count += 1
                print(f"  âœ… ÄÃ£ cáº­p nháº­t: {', '.join(updates)}")
            else:
                print(f"  âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ cáº­p nháº­t")
        
        print(f"\nğŸ‰ ÄÃ£ fix {fixed_count}/{len(books_data)} sÃ¡ch")
        
        # LÆ°u file má»›i
        fixed_file = json_file_path.replace('.json', '_fixed.json')
        with open(fixed_file, 'w', encoding='utf-8') as f:
            json.dump(books_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ÄÃ£ lÆ°u file Ä‘Ã£ fix: {fixed_file}")
        
        # Hiá»ƒn thá»‹ káº¿t quáº£
        print(f"\nğŸ“Š Káº¾T QUáº¢ SAU KHI FIX:")
        for i, book in enumerate(books_data, 1):
            print(f"{i}. {book['title']}")
            print(f"   - TÃ¡c giáº£: {book['author'] or 'ChÆ°a cÃ³'}")
            print(f"   - NXB: {book['publisher'] or 'ChÆ°a cÃ³'}")
            print(f"   - NÄƒm XB: {book['publish_year'] or 'ChÆ°a cÃ³'}")
            print(f"   - Sá»‘ trang: {book['page_count'] or 'ChÆ°a cÃ³'}")
            print(f"   - Trá»ng lÆ°á»£ng: {book['weight']} kg" if book['weight'] > 0 else "   - Trá»ng lÆ°á»£ng: ChÆ°a cÃ³")
            print()
        
        return books_data, fixed_file
        
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        return None, None

def update_database_with_fixed_data(books_data):
    """Cáº­p nháº­t database vá»›i dá»¯ liá»‡u Ä‘Ã£ fix"""
    print(f"\nğŸ—„ï¸ Cáº¬P NHáº¬T DATABASE")
    print("=" * 30)
    
    try:
        db = FahasaDatabase()
        
        # XÃ³a dá»¯ liá»‡u cÅ© vÃ  thÃªm dá»¯ liá»‡u má»›i
        import sqlite3
        conn = sqlite3.connect('fahasa_books.db')
        cursor = conn.cursor()
        
        # XÃ³a cÃ¡c sÃ¡ch cÃ³ URL trÃ¹ng (tá»« láº§n thu tháº­p trÆ°á»›c)
        urls_to_delete = [book['url'] for book in books_data]
        
        for url in urls_to_delete:
            cursor.execute('DELETE FROM books WHERE url = ?', (url,))
        
        conn.commit()
        conn.close()
        
        print(f"ğŸ—‘ï¸ ÄÃ£ xÃ³a dá»¯ liá»‡u cÅ©")
        
        # ThÃªm dá»¯ liá»‡u má»›i
        inserted = db.insert_books(books_data)
        print(f"âœ… ÄÃ£ thÃªm {inserted} sÃ¡ch Ä‘Ã£ fix vÃ o database")
        
        # Xuáº¥t Excel má»›i
        import time
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        excel_file = db.export_to_excel(f"fahasa_fixed_{timestamp}.xlsx")
        print(f"ğŸ“Š ÄÃ£ táº¡o file Excel má»›i: {excel_file}")
        
        # Thá»‘ng kÃª
        stats = db.get_statistics()
        print(f"\nğŸ“ˆ THá»NG KÃŠ DATABASE SAU KHI FIX:")
        print(f"- Tá»•ng sá»‘ sÃ¡ch: {stats['total_books']}")
        print(f"- SÃ¡ch cÃ³ tÃ¡c giáº£: {stats['books_with_author']}")
        print(f"- SÃ¡ch cÃ³ NXB: {stats['books_with_publisher']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Lá»—i cáº­p nháº­t database: {e}")
        return False

def fix_price_issue():
    """Giáº£i thÃ­ch vÃ  hÆ°á»›ng dáº«n fix váº¥n Ä‘á» giÃ¡"""
    print(f"\nğŸ’° Váº¤N Äá»€ Vá»€ GIÃ SÃCH")
    print("=" * 30)
    
    print("""
ğŸ” NGUYÃŠN NHÃ‚N GIÃ = 0:
  â€¢ CÃ¡c sÃ¡ch trong flashsale khÃ´ng hiá»ƒn thá»‹ giÃ¡ rÃµ rÃ ng
  â€¢ GiÃ¡ cÃ³ thá»ƒ Ä‘Æ°á»£c load báº±ng JavaScript
  â€¢ Cáº§n Ä‘Äƒng nháº­p hoáº·c cÃ³ session Ä‘áº·c biá»‡t
  â€¢ Selector CSS khÃ´ng chÃ­nh xÃ¡c

ğŸ› ï¸ CÃCH KHáº®C PHá»¤C:
  1. Thá»­ truy cáº­p sÃ¡ch khÃ´ng pháº£i flashsale
  2. Cáº£i thiá»‡n selector CSS cho giÃ¡
  3. ThÃªm delay Ä‘á»ƒ chá» JavaScript load
  4. Sá»­ dá»¥ng API náº¿u cÃ³
  5. Thu tháº­p tá»« trang danh má»¥c thay vÃ¬ chi tiáº¿t

ğŸ¯ THá»°C HIá»†N:
  â€¢ Cháº¡y script vÃ o giá» khÃ¡c (khÃ´ng flashsale)
  â€¢ Thá»­ URL khÃ¡c: /sach-trong-nuoc, /van-hoc
  â€¢ Kiá»ƒm tra DevTools Ä‘á»ƒ tÃ¬m selector Ä‘Ãºng
""")

def main():
    """HÃ m chÃ­nh"""
    print("ğŸ”§ FIX Dá»® LIá»†U FAHASA")
    print("=" * 40)
    
    # File JSON cáº§n fix
    json_file = "fahasa_limited_20251012_183401.json"
    
    if not os.path.exists(json_file):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file {json_file}")
        return
    
    # Fix dá»¯ liá»‡u JSON
    fixed_books, fixed_file = fix_json_data(json_file)
    
    if fixed_books:
        # Cáº­p nháº­t database
        success = update_database_with_fixed_data(fixed_books)
        
        if success:
            print(f"\nâœ… HOÃ€N THÃ€NH FIX Dá»® LIá»†U!")
            print(f"ğŸ“ File Ä‘Ã£ fix: {fixed_file}")
            print(f"ğŸ—„ï¸ Database Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t")
        
        # Giáº£i thÃ­ch váº¥n Ä‘á» giÃ¡
        fix_price_issue()
    
    print(f"\nğŸš€ TIáº¾P THEO:")
    print("1. Thá»­ cháº¡y script thu tháº­p khÃ´ng flashsale")
    print("2. Cáº£i thiá»‡n selector trong fahasa_limited_scraper.py")
    print("3. Thu tháº­p tá»« cÃ¡c trang danh má»¥c khÃ¡c")

if __name__ == "__main__":
    import os
    main()